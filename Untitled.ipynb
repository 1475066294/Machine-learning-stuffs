{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cd Desktop/data_hacking/dga_detection/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 设置绘图大小\n",
    "plt.rcParams['figure.figsize'] = (14.0, 5.0)\n",
    "plt.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取合法域名\n",
    "alexa_dataframe = pd.read_csv('data/alexa_100k.csv', names=['rank','url'], header=None, encoding='utf-8')\n",
    "alexa_dataframe.head() #读取出来所有的域名数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#提取域名\n",
    "import tldextract\n",
    "import numpy as np\n",
    "\n",
    "def domain_extract(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    if (not ext.suffix):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return ext.domain\n",
    "\n",
    "alexa_dataframe['domain'] = [ domain_extract(url) for url in alexa_dataframe['url']]\n",
    "del alexa_dataframe['rank']\n",
    "del alexa_dataframe['url']\n",
    "alexa_dataframe.count()\n",
    "alexa_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexa_dataframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexa_dataframe.isnull().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#发现有很多nan数据，丢弃\n",
    "alexa_dataframe = alexa_dataframe.dropna()\n",
    "#重复的域名数据对这次的训练没什么意义，所以抛弃\n",
    "alexa_dataframe = alexa_dataframe.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexa_dataframe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置分类\n",
    "alexa_dataframe['class'] = 'legit'\n",
    "#打乱数据\n",
    "alexa_dataframe = alexa_dataframe.reindex(np.random.permutation(alexa_dataframe.index))\n",
    "alexa_totol = alexa_dataframe.shape[0]\n",
    "print \"合法域名总数 %d\" %alexa_totol\n",
    "\n",
    "#据说掐头去尾后效果更好我们最后测试一下\n",
    "hole_out_alexa = alexa_dataframe[int(alexa_totol*.9):]\n",
    "alexa_dataframe = alexa_dataframe[:int(alexa_totol*.9)]\n",
    "print \"使用的合法域名总数 %d\" %alexa_dataframe.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexa_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######开始读取dga域名\n",
    "dga_dataframe = pd.read_csv('data/dga_domains.txt',names=['raw_domain'],header=None,encoding='utf-8')\n",
    "dga_dataframe.head()\n",
    "#print dga_dataframe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [domain_extract(url) for url in dga_dataframe['raw_domain']]\n",
    "test = pd.DataFrame(test)\n",
    "print dga_dataframe.count()\n",
    "test.count()\n",
    "#很明显从测试的结果来看，直接用tldextract提取dga域名效果差极了，我们注意到域名可以似乎直接通过.分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分割出域名\n",
    "dga_dataframe['domain'] = dga_dataframe.applymap(lambda x: x.split('.')[0].lower())\n",
    "#print dga_dataframe.head()\n",
    "del dga_dataframe['raw_domain']\n",
    "#删除为空和重复的数据\n",
    "dga_dataframe = dga_dataframe.dropna()\n",
    "dga_dataframe = dga_dataframe.drop_duplicates()\n",
    "dga_totol = dga_dataframe.shape[0]\n",
    "print \"dga 域名总数为 %d\" %dga_totol\n",
    "#print dga_dataframe.head()\n",
    "\n",
    "#设置分类\n",
    "dga_dataframe['class'] = 'dga'\n",
    "#听说掐头去尾效果更好。\n",
    "hold_out_dga = dga_dataframe[int(dga_totol*0.9):]\n",
    "dga_dataframe = dga_dataframe[:int(dga_totol*0.9)]\n",
    "print \"使用的域名总数为 %d\" %dga_dataframe.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dga_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把所有域名链接到一起\n",
    "all_domains = pd.concat([alexa_dataframe,dga_dataframe],ignore_index=True)\n",
    "print all_domains.head()\n",
    "all_domains.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从之前可以看到合法域名和dga域名有着明显长度区别。\n",
    "all_domains['length'] = [len(x) for x in all_domains['domain']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "#熵的计算公式\n",
    "def entropy(x):\n",
    "    p,lns = Counter(x) ,float(len(x))\n",
    "    return -sum(count/lns * math.log(count/lns,2) for count in p.values())\n",
    "#同样，将域名的信息熵作为一个特征\n",
    "all_domains['entropy'] = [entropy(x) for x in all_domains['domain']]\n",
    "all_domains.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_domains.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################开始绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通过盒图来查看整个数据分布\n",
    "import matplotlib.pylab as plt\n",
    "all_domains.boxplot('length','class')\n",
    "plt.ylabel('length')\n",
    "all_domains.boxplot('entropy','class')\n",
    "plt.ylabel('entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cond = all_domains['class'] == 'dga'\n",
    "dga = all_domains[cond]\n",
    "alexa = all_domains[~cond]\n",
    "plt.scatter(alexa['length'],alexa['entropy'],s=140,c='#aaaaff',label='Alexa',alpha=.2)\n",
    "plt.scatter(dga['length'],dga['entropy'],s=40,c='r',label='dga',alpha=.3)\n",
    "plt.xlabel('domain length')\n",
    "plt.ylabel('domain entropy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建训练X输入矩阵\n",
    "X = all_domains.as_matrix(['length','entropy'])\n",
    "#构建y结果\n",
    "y= np.array(all_domains['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "clf = sklearn.ensemble.RandomForestClassifier(n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(clf,X,y,cv=5,n_jobs=4)\n",
    "print scores\n",
    "#emmmmm这个大概97.5的准确率甚是喜人啊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "#取一个8比2的分割来通过混淆矩阵看一下预测效果\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = ['legit','dga']\n",
    "cm = confusion_matrix(y_test,y_pred,labels)\n",
    "print \"legit     dga\"\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##但是我们看到几乎所有的域名都被分到合法区域，对dga的探测效果非常差\n",
    "##试试增加更多的特征能不能提升效果\n",
    "##利用文本分析来创建特征,首先提取通用向量\n",
    "alexa_vc = sklearn.feature_extraction.text.CountVectorizer(analyzer = 'char')\n",
    "alexa_vc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### NGrams算法\n",
    "counts_matrix = alexa_vc.fit_transform(alexa_dataframe['domain'])\n",
    "alexa_counts = np.log10(counts_matrix.sum(axis=0).getA1())\n",
    "ngrams_list = alexa_vc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建字典\n",
    "word_dataframe = pd.read_csv('data/words.txt',names=['word'],header=None,dtype={'word':np.str},encoding='utf-8')\n",
    "#################高能注意##############\n",
    "#word_dataframe = word_dataframe[word_dataframe['word'].map(lambda x: str(x).isalpha())]\n",
    "word_dataframe = word_dataframe.applymap(lambda x: str(x).lower())\n",
    "word_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_vc = sklearn.feature_extraction.text.CountVectorizer(analyzer='char', ngram_range=(3,5), min_df=1e-5, max_df=1.0)\n",
    "counts_matrix = dict_vc.fit_transform(word_dataframe['word'])\n",
    "dict_counts = np.log10(counts_matrix.sum(axis=0).getA1())\n",
    "ngrams_list = dict_vc.get_feature_names()\n",
    "ngrams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_count(domain):\n",
    "    alexa_match = alexa_counts * alexa_vc.transform([domain]).T\n",
    "    dict_match = dict_counts * dict_vc.transform([domain]).T\n",
    "    print '%s Alexa match %d Dict match: %d' %(domain,alexa_match,dict_match)\n",
    "##测试一些例子\n",
    "# Examples:\n",
    "ngram_count('google')\n",
    "ngram_count('facebook')\n",
    "ngram_count('1cb8a5f36f')\n",
    "ngram_count('pterodactylfarts')\n",
    "ngram_count('ptes9dro-dwacty2lfa5rrts')\n",
    "ngram_count('beyonce')\n",
    "ngram_count('bey666on4ce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_domains['alexa_grams'] = alexa_counts * alexa_vc.transform(all_domains['domain']).T\n",
    "all_domains['word_grams'] = dict_counts * dict_vc.transform(all_domains['domain']).T    \n",
    "all_domains.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_domains.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#总会有存在两个ngram差值不存在的位置\n",
    "all_domains['diff'] = all_domains['alexa_grams'] - all_domains['word_grams']\n",
    "all_domains.sort_values(['diff'],ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_domains.sort_values(['diff'], ascending=False).head(30)\n",
    "#很好，差值得划分出了dga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############绘图时间\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = all_domains['class'] == 'dga'\n",
    "dga = all_domains[cond]\n",
    "legit = all_domains[~cond]\n",
    "plt.scatter(legit['entropy'], legit['alexa_grams'],  s=120, c='#aaaaff', label='Alexa', alpha=.2)\n",
    "plt.scatter(dga['entropy'], dga['alexa_grams'], s=40, c='r', label='DGA', alpha=.3)\n",
    "plt.legend()\n",
    "plt.xlabel('Domain Entropy')\n",
    "plt.ylabel('Alexa Gram Matches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = all_domains['class'] == 'dga'\n",
    "dga = all_domains[cond]\n",
    "legit = all_domains[~cond]\n",
    "plt.scatter(legit['length'], legit['alexa_grams'], s=120, c='#aaaaff', label='Alexa', alpha=.1)\n",
    "plt.scatter(dga['length'], dga['alexa_grams'], s=40, c='r', label='DGA', alpha=.3)\n",
    "plt.legend()\n",
    "plt.xlabel('Domain Length')\n",
    "plt.ylabel('Alexa NGram Matches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = all_domains['class'] == 'dga'\n",
    "dga = all_domains[cond]\n",
    "legit = all_domains[~cond]\n",
    "plt.scatter(legit['word_grams'], legit['alexa_grams'], s=120, c='#aaaaff', label='Alexa', alpha=.1)\n",
    "plt.scatter(dga['word_grams'], dga['alexa_grams'], s=40, c='r', label='DGA', alpha=.3)\n",
    "plt.legend()\n",
    "plt.xlabel('Domain Length')\n",
    "plt.ylabel('Alexa NGram Matches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_domains[(all_domains['word_grams']==0)].head()\n",
    "print 'test'\n",
    "###在word_gram ==0及完全匹配到dict的域名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用我们现在的四个特征。不对，五个特征试试cm值是否可观\n",
    "X = all_domains.as_matrix(['length','entropy','alexa_grams','word_grams'])\n",
    "y = np.array(all_domains['domain'].tolist())\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "labels = ['legit','dga']\n",
    "cm = confusion_matrix(y_test,y_pred,labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
